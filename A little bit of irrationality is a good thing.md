*start with the luigi case on murder*

Imagine you had a perfect simulator that could tell you, beyond question, the results of your actions. You would make a pretty stellar consequentialist, since you could just simulate all the courses of action available to you and choose the action with the best outcome. Does it follow that the ideal consequentialist world is one in which everyone has such a simulator?

Of course not. Let’s imagine there are just two people in this perfectly rational world. You’re both trying to make a simple decision, for instance, what side of the road to drive on. But in order to tell him what to do, his simulation must know what your simulation will say. But the reverse is true for you! Both simulations require the output of the other to give their final answer, and they will get stuck.

The simple fix for this is to put aside the consequences in your decision-making calculus, and to instead mindlessly follow a *rule*. A rule that says, ‘trust us. drive on the right’. 

You might think that driving on the right is an artificially constructed example, and that in general, reasoning based on the consequences is a safe bet. But these sorts of coordination scenarios (where knowing what is right depends on knowing what the other person will do) arise all the time. Here are a few examples, spanning from the frivolous to the serious:
- *how late should you be for a lunch date with a friend?* Here, the answer depends on how late your friend will be. If your friend will be five minutes late, better for you to be five minutes late than to be on time. But if your friend is on time, the opposite is true. This is likely why cultures tend to have a norm when it comes to punctuality, and that norm varies widely from german punctuality to . Neither one is the right answer; what matters is that everyone know what to expect. 
- *should you sell tobacco products as a convenience store owner?* If you think that the other convenience stores might also refrain from selling, then you’re making it harder to smoke, which could reduce smoking rates. But if you think the other convenience stores will continue selling, smokers can just go to other convenience stores with minimal additional hassle. Now you lose business, smoking rates stay the same, and the more unscrupulous convenience store owners have more money than you. In such cases (if the convenience store owners are virtuous) they might all favor a rule forbidding them from selling tobacco
- *how often should the IRS audit to ensure tax compliance?* Here, the IRS is wondering to what extent a decrease in enforcement will lead to a decrease in compliance. Individual taxpayers are wondering how likely a decrease in compliance is to result in a tax audit. 
- A common question [^1]
- is political violence justified? is this really a coordination question? well let’s see. suppose some people choose violence but others not . if political violence is accepted in a particular time. well, maybe if you know you’re right, and doing something will have good consequences, then you do it. but this relies 

The interesting thing is, you can still make a consequentialist case for these rules, but it is likely that you *shouldn’t*. Because if you do, there will always be times and places where it is obvious that breaking the rule will have immediate benefits, and it will be very tempting to break them. But in doing so, the sanctity of the rule is weakened. And if it gets weakened to the point where people can no longer rely on it, it ceases to have a positive effect. 

Of course, it is possible to say that people should only break the rule if they know that whatever weakening of the rule that results . [why this gets us back where we started] Well the other person is thinking, to what extent should I stop following the rule. But this requires simulating you. and let’s say you, in the future, are doing this same simulation. and you have to simulate the other person. but the result of their simulation depends on what you do

- two ways to look at it: it requires simulating yourself, which seems impossible.
- or, it requires simulating knowing the output of the other person’s simulation. but the other person’s simulation requires your simulation’s output

then, is this a justification of centralized authority for setting the rules. certainly, centralized authority is one way. but there are many ways that norms can stabilize. that said, probably centralized decree is most effective. what about *agency* and computation tho

morality as a contract
kant 
remark about large numbers
seems like two things are going on: coordination and public good. i think the difference is that in one case, one of the coordination outcomes is “better”
sometimes while you may not get the abstract perfection of a coordination game, it’s still the case that 

what’s the problem here. you have to simulate what the other person will do. but they have to simulate what you will do, and will act accordingly. this means that you have to simulate yourself. ok fine. can this lead to a contradiction where basically my simulation can’t tell me what to do because no matter what I do, 

i mean the structure i want to imitate is the halting problem, where basically whatever the 

really what I want to see is that whatever you *think* is the right thing is actually the wrong thing, and whatever you think is the wrong this is actually right. of course, if you have an immoral agent, they can just turn whatever choice you make into the bad choice. But really I want a case where there are two people who mean well that want to decide how to act based on the consequences. 

does things being sequential change things?
## question
why does the irs example not exactly work? because im working at two different levels. of course if i went at the same level and i said ok suppose the irs is auditing a particular taxpayer. then the taxpayer has 

can i do something on the individual level with welfare? here it would be the government worker deciding whether to give someone welfare assistance, and the person deciding how to behave. (how hard to look for a job, for instance). 

#### A societal subjectivity
In a case like this, no single person has the true morality in their head. 

how can I do the welfare example 

[^1]:There are of course other dynamics at play here, including the [[tragedy of the commons|tragedy of the commons]]. While it might make sense for welfare recipients as a whole not to abuse the welfare system for fear that benefits will be cut, welfare recipients do not act as a whole. Individual welfare recipients may still think that the negligible 